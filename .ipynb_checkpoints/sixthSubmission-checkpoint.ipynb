{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c0b09fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from typing import Optional\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8d1b450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_location = f'./local'\n",
    "train_file_name = 'train.csv'\n",
    "test_file_name = 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ef59eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(data_location, train_file_name))\n",
    "df_test = pd.read_csv(os.path.join(data_location, test_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832751e6",
   "metadata": {},
   "source": [
    "### Data Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f3067e",
   "metadata": {},
   "source": [
    "step 1. remove outliers, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbd25bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_train[['SalePrice', 'GrLivArea']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ca312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = sns.pairplot(df_train[['SalePrice', 'GrLivArea']])\n",
    "img.fig.set_size_inches(15,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dc35be",
   "metadata": {},
   "outputs": [],
   "source": [
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce5f14b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it should be a linear relationship between sales price and ground live area\n",
    "# there are exceptional cases where it should be dropped from the training set\n",
    "df_train.drop(df_train[(df_train['SalePrice'] < 300000) & (df_train['GrLivArea'] > 4000)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f6e906",
   "metadata": {},
   "source": [
    "step 2. fill null columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2dad911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LotFrontage', 'Alley', 'MasVnrType', 'MasVnrArea', 'BsmtQual',\n",
       "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
       "       'Electrical', 'FireplaceQu', 'GarageType', 'GarageYrBlt',\n",
       "       'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence',\n",
       "       'MiscFeature'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns[df_train.isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9398bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MSZoning', 'LotFrontage', 'Alley', 'Utilities', 'Exterior1st',\n",
       "       'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond',\n",
       "       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n",
       "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath',\n",
       "       'BsmtHalfBath', 'KitchenQual', 'Functional', 'FireplaceQu',\n",
       "       'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea',\n",
       "       'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature',\n",
       "       'SaleType'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns[df_test.isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fe5445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on data description file, several fields\n",
    "# are expected to be null provided it means No\n",
    "# such features.\n",
    "fill_none_cols = ['Alley', 'MasVnrType',  'BsmtQual', 'BsmtCond', 'BsmtExposure',\n",
    "                  'BsmtFinType1', 'BsmtFinType2', 'FireplaceQu','GarageType', \n",
    "                  'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence',\n",
    "                  'MiscFeature']\n",
    "fill_zero_cols = ['MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
    "                  'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'GarageYrBlt',\n",
    "                  'GarageCars', 'GarageArea', ]\n",
    "fill_freq_cols = ['MSZoning', 'Utilities', 'Exterior1st', 'Exterior2nd',\n",
    "                  'KitchenQual', 'Functional', 'SaleType', 'Electrical']\n",
    "fill_med_cols = ['LotFrontage']\n",
    "to_str_cols = ['MSSubClass', 'OverallCond', 'YrSold', 'MoSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bc62c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fill_missing_fields(df: pd.DataFrame, \n",
    "                        fill_none_cols: Optional[list] = None, \n",
    "                        fill_zero_cols: Optional[list] = None, \n",
    "                        fill_freq_cols: Optional[list] = None,\n",
    "                        fill_med_cols: Optional[list] = None) -> pd.DataFrame:\n",
    "    freq_impute = SimpleImputer(strategy='most_frequent')\n",
    "    med_impute = SimpleImputer(strategy='median')\n",
    "    \n",
    "    df[fill_none_cols] = df[fill_none_cols].fillna('None')\n",
    "    df[fill_zero_cols] = df[fill_zero_cols].fillna(0)\n",
    "    df[fill_freq_cols] = freq_impute.fit_transform(df[fill_freq_cols])\n",
    "    df[fill_med_cols] = med_impute.fit_transform(df[fill_med_cols])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74191328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _change_dtype(df: pd.DataFrame, \n",
    "                  to_str_cols: Optional[list] = None) -> pd.DataFrame:\n",
    "    df[to_str_cols] = df[to_str_cols].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1adb87e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(df: pd.DataFrame,\n",
    "                fill_none_cols: Optional[list] = None, \n",
    "                fill_zero_cols: Optional[list] = None, \n",
    "                fill_freq_cols: Optional[list] = None,\n",
    "                fill_med_cols: Optional[list] = None,\n",
    "                to_str_cols: Optional[list] = None) -> pd.DataFrame:\n",
    "    df = _fill_missing_fields(df, fill_none_cols, fill_zero_cols,\n",
    "                             fill_freq_cols, fill_med_cols)\n",
    "    df = _change_dtype(df, to_str_cols)\n",
    "    assert len(df.columns[df.isnull().sum()>0])==0, (\"still missing field(s) in the dataframe\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1521b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot transformation\n",
    "def one_hot_encode(df: pd.DataFrame):\n",
    "    newDF = df.copy()\n",
    "    obj_cols = list(newDF.select_dtypes(include='object'))\n",
    "    try: obj_cols.remove('type')\n",
    "    except: pass\n",
    "    for col in obj_cols:\n",
    "        dummies = pd.get_dummies(newDF[col], prefix=col)\n",
    "        newDF = pd.concat([newDF, dummies], axis=1)\n",
    "        newDF.drop(columns=col, inplace=True)\n",
    "    return newDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc528c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = transform_df(df_train, fill_none_cols, fill_zero_cols,\n",
    "                        fill_freq_cols, fill_med_cols, to_str_cols)\n",
    "df_test = transform_df(df_test, fill_none_cols, fill_zero_cols,\n",
    "                       fill_freq_cols, fill_med_cols, to_str_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42923fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine train and test dataframe for one-hot encoding\n",
    "# the combination prevents values in test set does not\n",
    "# exist in train set\n",
    "df_train['type'] = 'train'\n",
    "df_test['type'] = 'test'\n",
    "df_merge = pd.concat([df_train, df_test], ignore_index=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb2bd7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_label = ['Alley','BsmtQual', 'BsmtCond', 'BsmtFinType1', 'BsmtFinType2', 'BsmtExposure',\n",
    "                 'CentralAir', 'ExterQual', 'ExterCond', 'Fence', 'FireplaceQu', 'Functional',\n",
    "                 'GarageQual', 'GarageCond', 'GarageFinish', 'HeatingQC', 'KitchenQual',  \n",
    "                 'LandSlope', 'LotShape', 'MoSold', 'MSSubClass', 'OverallCond', \n",
    "                 'PavedDrive', 'PoolQC', 'Street', 'YrSold', ]\n",
    "for col in cols_to_label:\n",
    "    label = LabelEncoder()\n",
    "    df_merge[col] = label.fit_transform(list(df_merge[col].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec9cc891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2917, 224)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge = one_hot_encode(df_merge)\n",
    "df_merge = df_merge.loc[:,~df_merge.columns.duplicated()]\n",
    "df_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7315f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop high correlation columns\n",
    "tmp = df_merge.corr().abs()[df_merge.corr().abs() != 1].unstack()\n",
    "cols_high_corr = list(tmp[tmp >.8].sort_values(ascending=False).drop_duplicates().unstack().columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "943e9daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2917, 207)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.drop(columns=cols_high_corr, inplace=True)\n",
    "df_merge.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f3b795",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de97742f",
   "metadata": {},
   "source": [
    "As the dataset does not contain so many records but with relatively large amount of features, Support vector machines are used in such scenarios. In particular, NuSVR will be used by using parameter Nu to control the number of support vectors.<br>\n",
    "Therefore, data cleansing/preprocessing is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1bc697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cd509cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_x = StandardScaler()\n",
    "standard_y = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5b41ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_irrelevant = ['type', 'Id']\n",
    "x_col = list(df_merge.columns)\n",
    "y_col = 'SalePrice'\n",
    "for col in cols_irrelevant:\n",
    "    x_col.remove(col)\n",
    "x_col.remove(y_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ecb88a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform features\n",
    "standard_x.fit(df_merge[x_col])\n",
    "df_merge[x_col] = standard_x.transform(df_merge[x_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ac4fab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform target\n",
    "standard_y.fit(np.array(df_merge[y_col]).reshape(-1,1))\n",
    "df_merge[y_col] = standard_y.transform(np.array(df_merge[y_col]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ee2a1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_merge[df_merge['type'] == 'train']\n",
    "df_test = df_merge[df_merge['type'] == 'test']\n",
    "df_train.drop(columns='type', inplace=True)\n",
    "df_test.drop(columns='type', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa5cd2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1458, 206)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591a93d8",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11fee045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02453768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be9c8c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "model = Sequential(name='Simple_Regression_Model')\n",
    "model.add(Input(len(x_col)))\n",
    "model.add(Dense(128, activation=tf.nn.relu, kernel_initializer='he_uniform'))\n",
    "model.add(Dense(64, activation=tf.nn.relu))\n",
    "model.add(Dense(32, activation=tf.nn.relu))\n",
    "model.add(Dense(8, activation=tf.nn.relu))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss = root_mean_squared_error, optimizer='Adam', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4990f8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Simple_Regression_Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               26240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 36,849\n",
      "Trainable params: 36,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d02bb158",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('val_mse')<.01):\n",
    "            print('MSE of validation set is smaller than 1%')\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callback_model = Callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "164d0aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(df_train[x_col].values, df_train[y_col].values, \n",
    "                    validation_split=.1,\n",
    "                    epochs=1000, \n",
    "                    batch_size=10,\n",
    "                    callbacks=[callback_model],\n",
    "                    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0425f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training behavior\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epochs'] = history.epoch\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(hist['epochs'], hist['mse'], label='Training MSE')\n",
    "plt.plot(hist['epochs'], hist['val_mse'], label='Validation MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model Performance')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26761677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store trained result\n",
    "filename = './model/sixthSubmission.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4aff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate result dataframe\n",
    "df_test['y_pred'] = standard_y.inverse_transform(model.predict(df_test[x_col]))\n",
    "submission = df_test[['Id', 'y_pred']].rename(columns={'y_pred':y_col})\n",
    "submission.to_csv('./submission/sixthSubmission.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c397d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
